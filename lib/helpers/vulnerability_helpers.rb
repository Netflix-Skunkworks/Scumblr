def escape_markdown_characters(text)

  ["\\","#"].each do |char|
    text = text.gsub(char,"\\"+char)
  end
  return text
end

class Vulnerability
  attr_accessor :id, :name, :external_link,
    :external_id, :type, :source, :severity,
    :identified, :status, :attack_vectors,
    :url, :confidence_level, :source_code_file,
    :source_code_line, :source_code, :details, :term,
    :score, :file_path, :file_name, :task_name, :task_id,
    :key_suffix, :code_fragment, :match_location, :before,
    :after, :line_number, :status_code, :path,
    :reporter, :reward, :jira_ids, :payload, :app, :negative,
    :fingerprint, :commit_email, :commit_name, :commit_branch, :match_count, :regex

  def initialize
    @attack_vectors=[]
    @identified = Time.now
    @status = "Open"
    @id = SecureRandom.hex
  end

  def is_valid?
    true
  end



end

class AttackVector

  attr_accessor :type, :name, :method, :payload, :note

  def initialize

  end


end

Result.class_eval do

  before_save :vulnerability_counter
  def vulnerability_counter
    if self.changes.include? "metadata"
      # puts self.changes
      if self.changes.try(:[], "metadata").try(:first).try(:[], "vulnerabilities").nil? || (self.changes.try(:[], "metadata").try(:last).try(:[], "vulnerabilities").blank? && self.changes.try(:[], "metadata").try(:last).try(:[], "vulnerabilities_count").blank?)
        return
      end
      unless (self.changes.try(:[], "metadata").try(:first).try(:[], "vulnerabilities").to_a - self.changes.try(:[], "metadata").try(:last).try(:[], "vulnerabilities").to_a).blank?
        self.update_vulnerabilities([], false)
      end
    end
    return true
  end

  def update_sitemap(sitemap=[], source_name=nil)

    self.metadata["sitemap"] ||= []

    sitemap.each do |url|

      entry = self.metadata["sitemap"].select{|entry| entry["url"] == url}.first
      if(!entry)
        entry = {}
        entry["url"] = url
        entry["identified"] = entry["last_seen"] = Time.now
        begin
          uri = URI.parse(url)
          entry["scheme"] = uri.scheme
          entry["host"] = uri.host

          path = uri.path.split("/")
          if(path.last.to_s.include?("."))
            entry["endpoint"] = path.pop
          end

          entry["path"] = path.blank? ? "/" : path.join("/")
          entry["source"] = source_name if source_name

        rescue
        end
        self.metadata["sitemap"] << entry
      else
        entry["last_seen"] = Time.now
        entry["source"] ||= source_name if source_name
      end
    end



  end

  # Add a set of vulnerabilities to the
  def add_scan_vulnerabilities(vulnerabilities, sitemap, source_name, task_id, auto_remediate=false, options={})

    updated_ids, vulnerability_statuses = update_vulnerabilities(vulnerabilities, false, false, options)
    vulnerability_statuses["closed"] ||= 0
    update_sitemap(sitemap, source_name) if sitemap

    if(auto_remediate && open_vulnerabilities.present?)

      open_vulnerabilities.select{|v| v["task_id"].to_s == task_id.to_s && !updated_ids.include?(v["id"])}.each{|v|
        v["status"] = "Auto Remediated"

        vulnerability_statuses["closed"] += 1
      }
    end

    self.metadata["scan_metadata"] ||= []
    self.metadata["scan_metadata"] << {parsed: Time.now, source: source_name, task_id: task_id }.merge(vulnerability_statuses)



    update_vulnerability_counts

    update_trends


    self.save


    return vulnerability_statuses

  end

  def update_vulnerabilities(vulnerabilities=[], save_result=true, update_counts=true, options={})

    vulnerability_status = {"existing" => 0, "new"=> 0, "reopened"=> 0,"regression"=> 0}
    updated_ids = []
    self.metadata ||={}
    self.metadata["vulnerabilities"] ||=[]

    self.metadata["vulnerabilities"].each do |vuln|

      unless vuln.try(:[], "jira_ids").to_s == ""
        vuln["jira_ids"] = vuln["jira_ids"].gsub(/\s+/, "").upcase
      end
    end

    vulnerabilities.each do |v|

      r = find_duplicate_vulnerability(v, options)

      if(r.present?)
        r = r.first

        r["id"] ||= SecureRandom.hex
        updated_ids << r["id"]
        r["source"] ||= []
        if(!r["source"].include?(v.source))
          r["source"] << v.source
          r["source"].uniq!
        end

        r["external_link"] ||={}
        r["external_link"].merge(v.external_link || {})

        v.attack_vectors.each do |vector|
          r["attack_vectors"] ||=[]
          existing_vector = find_duplicate_attack_vector(r["attack_vectors"], v, vector)
          if(existing_vector.blank?)
            r["attack_vectors"] << JSON.parse(vector.to_json)
          end

        end

        if(r["status"].to_s.match /Remediated/)
          # Mark "Remediated" or "Auto Remediated" as Reopened
          vulnerability_status["regression"] += 1
          r["status"] = "Reopened"
        elsif(r["status"] == "False Positive" && (Time.now - Time.parse(r["identified"])) > 30.days)
          # Reopen False Positives that are re-identified more than 30 days later
          # TODO: Make this logic configurable
          vulnerability_status["reopened"] += 1
          r["status"] = "Reopened"
          r["identified"] = Time.now
        else
          vulnerability_status["existing"] += 1
        end

        r["reporter"] = v.reporter if v.reporter
        r["reward"] = v.reward if v.reward

        r["fingerprint"] = v.fingerprint if v.fingerprint

        # Do not want to overwrite existing details
        # r["details"] = v.details

      else
        vulnerability_status["new"] += 1
        v.identified = Time.now
        v.id = SecureRandom.hex
        updated_ids << v.id
        v.severity = v.severity.to_s.titleize
        if(v.source.class == String || v.source.class == Array)
          v.source = Array(v.source).uniq
        else
          v.source = [v.source].uniq
        end


        self.metadata["vulnerabilities"] << JSON.parse(v.to_json)

      end
    end

    update_vulnerability_counts if update_counts



    if save_result
      self.save
    end

    return [updated_ids, vulnerability_status]

  end

  def update_vulnerability_counts


    task_counts = Hash.new(0)
    source_counts = Hash.new(0)
    key_suffix_counts = Hash.new(0)


    self.metadata["vulnerabilities"] ||= []

    open_vulnerabilities = self.open_vulnerabilities
    closed_count = self.metadata["vulnerabilities"].select{|v| !v["status"].to_s.match(/open/i) }.count

    informational_count = self.metadata["vulnerabilities"].select{|v| v["status"].to_s.match(/open/i) && v["severity"].to_s.downcase == "informational"}.count

    severity_counts = Hash.new(0).merge({"critical" => 0, "high" => 0, "medium" =>0, "low" => 0, "informational" => informational_count, "observational" => 0})

    status_count = {"open"=> open_vulnerabilities.length, "closed"=>closed_count}

    open_vulnerabilities.each { |v|
      if(v["key_suffix"].present?)
        key_suffix_counts[v["key_suffix"]] += 1
      end
      if(v["task_id"].present?)
        task_counts[v["task_id"]] += 1
      end
      if(v["source"].present? && v["source"].class == Array)
        v["source"].each do |s|
          source_counts[s] += 1
        end
      end
      if(v["severity"].present?)
        severity_counts[v["severity"].to_s.downcase] += 1
      end
    }

    self.metadata["vulnerability_count"] ||={}
    self.metadata["vulnerabilities"] ||=[]
    self.metadata["vulnerability_count"]["severity"] = severity_counts
    self.metadata["vulnerability_count"]["key_suffix"] = key_suffix_counts
    self.metadata["vulnerability_count"]["task_id"] = task_counts
    self.metadata["vulnerability_count"]["source"] = source_counts
    self.metadata["vulnerability_count"]["status"] = status_count
    return

  end

  def update_trends
    self.metadata["trends"] ||={"open_vulnerabilities" => {"data" =>[{"name"=> "open","data"=>{},"library"=>{"steppedLine"=>true}  }]}}
    self.metadata["trends"]["open_vulnerabilities"]["data"].first["data"][Time.now.strftime("%b %d %Y %H:%M:%S")] = self.open_vulnerabilities.count
  end

  def open_vulnerabilities
    begin
      self.metadata["vulnerabilities"].select{|v| v["status"].to_s.match(/open/i) && v["severity"].to_s.downcase != "informational"}
    rescue
      []
    end
  end

  def auto_remediate(task_id, options={})
    if(task_id.present? && self.metadata.try(:[],"vulnerabilities").present?)
      results = self.metadata["vulnerabilities"].select{|v| v["task_id"] == task_id}
      options.each do |key,value|
        results = results.select{|v| v[key] == value}
      end
      result.each {|v| v["status"] = "Auto Remediated"}
    end
  end

  def auto_remediate(task_id, url, term=nil, payload=nil)
    if self.metadata.try(:[],"vulnerabilities").present?
      if term.to_s == "" and payload.to_s == ""
        self.metadata["vulnerabilities"].each_with_object({}) do |vuln|
          if vuln["url"] == url && vuln["task_id"] == task_id

            vuln["status"] = "Auto Remediated"
          end
        end
      elsif payload.to_s == ""
        self.metadata["vulnerabilities"].each_with_object({}) do |vuln|
          if vuln["url"] == url && vuln["task_id"] == task_id && vuln["term"] == term
            vuln["status"] = "Auto Remediated"
          end
        end
      elsif term.to_s == ""
        self.metadata["vulnerabilities"].each_with_object({}) do |vuln|
          if vuln["url"] == url && vuln["task_id"] == task_id && vuln["payload"] == payload
            vuln["status"] = "Auto Remediated"
          end
        end
      else
        self.metadata["vulnerabilities"].each_with_object({}) do |vuln|
          if vuln["url"] == url && vuln["task_id"] == task_id && vuln["term"] == term && vuln["payload"] == payload
            vuln["status"] = "Auto Remediated"
          end
        end
      end
    end

    if self.changed?
      self.save!
    end
  end


  def find_duplicate_vulnerability(vulnerability, options={})
    # locations: content, path, headers
    # code_fragment

    # For some tasks, like curl we don't want to find duplicates if they came from other tasks.
    if(options.try(:[],:isolate_vulnerabilities) == true)
      existing_vulnerabilities = self.metadata["vulnerabilities"].select{|v| v["task_id"] == vulnerability.task_id}
    else
      existing_vulnerabilities = self.metadata["vulnerabilities"]
    end

    case vulnerability.match_location
    when "content"
      # This is a static analyzer match for content
      existing_vulnerabilities.select{|v| v["url"] == vulnerability.url && v["code_fragment"] == vulnerability.code_fragment && v["term"] == vulnerability.term }
    when "path"
      # This is a static analyzer match for paths
      existing_vulnerabilities.select{|v| v["url"] == vulnerability.url && v["term"] == vulnerability.term}
    when "headers"
      # This matches curl analyzers running on headers
      existing_vulnerabilities.select{|v| v["url"] == vulnerability.url && v["term"] == vulnerability.term}
    when "fingerprint"
      # This is the Rails analyzer fingerprint matcher with fallback
      existing_vulnerabilities.select do |v|
        if v["url"] != vulnerability.url
          false
        elsif v["fingerprint"] && v["fingerprint"] == vulnerability.fingerprint
          true
        else
          # Fall back on heuristics until fingerprint updated
          ["severity", "type", "source_code_file", "source_code_line"].all? do |data|
            v[data] == vulnerability.send(data.to_sym)
          end
        end
      end
    else
      existing_vulnerabilities.select{|v| v["url"] == vulnerability.url && v["type"] == vulnerability.type}
    end
  end

  def find_duplicate_attack_vector(vector_metadata, vulnerability, vulnerability_vector)
    vector_metadata.select{|v| v["type"] == vulnerability_vector.type && v["name"] == vulnerability_vector.name }
  end

end
